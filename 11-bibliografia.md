### 11. Bibliografia

#### 11.1. **Podręczniki akademickie i książki**
Książki akademickie często dostarczają kompleksowego zrozumienia teoretycznych podstaw algorytmów uczenia maszynowego oraz ich praktycznych zastosowań.

- **"Pattern Recognition and Machine Learning" – Christopher M. Bishop (2006)**
  - Klasyczna książka wprowadzająca do probabilistycznych modeli i algorytmów uczenia maszynowego. Dostarcza szczegółowych informacji na temat różnych metod, w tym algorytmów klasyfikacji, regresji i modelowania danych sekwencyjnych.
  
- **"The Elements of Statistical Learning: Data Mining, Inference, and Prediction" – Trevor Hastie, Robert Tibshirani, Jerome Friedman (2009)**
  - Ta książka jest jednym z najlepszych źródeł dotyczących statystycznego uczenia maszynowego, algorytmów zespołowych (ensemble), oraz wyboru odpowiednich metod w zależności od problemu. Zawiera również szczegółowe opisy technik regularyzacji i tuningu algorytmów.

- **"Machine Learning: A Probabilistic Perspective" – Kevin P. Murphy (2012)**
  - Książka ta skupia się na probabilistycznych metodach w uczeniu maszynowym, takich jak ukryte modele Markowa (HMM) czy modele Bayesowskie, oraz omawia zastosowanie różnych algorytmów w praktyce. Jest bardzo przydatna do wyboru algorytmu na podstawie natury danych i problemu.

#### 11.2. **Artykuły naukowe**
Dostęp do artykułów naukowych pozwala na dogłębne zrozumienie nowych algorytmów oraz ich porównanie z tradycyjnymi metodami.

- **"A Few Useful Things to Know about Machine Learning" – Pedro Domingos (2012)**
  - Ten artykuł dostarcza cennych wskazówek praktycznych na temat wyboru algorytmu oraz nawigacji po świecie uczenia maszynowego. Autor omawia kluczowe koncepcje, takie jak overfitting, złożoność obliczeniowa i zasady działania najczęściej używanych algorytmów.

- **"Random Forests" – Leo Breiman (2001)**
  - Artykuł wprowadzający koncepcję lasów losowych (Random Forest), który jest jednym z najczęściej stosowanych algorytmów zespołowych. Pomaga zrozumieć, dlaczego Random Forest jest tak skuteczny w wielu różnych zadaniach klasyfikacyjnych i regresyjnych.

- **"XGBoost: A Scalable Tree Boosting System" – Tianqi Chen, Carlos Guestrin (2016)**
  - To publikacja wprowadzająca algorytm XGBoost, który jest bardzo popularny w konkursach uczenia maszynowego ze względu na swoją wydajność i zdolność do modelowania złożonych zależności w danych.

#### 11.3. **Platformy e-learningowe i kursy online**
Kursy online pozwalają na zdobycie wiedzy praktycznej, często prowadzonej przez ekspertów z branży.

- **Coursera: "Machine Learning" – Andrew Ng**
  - Jeden z najbardziej znanych kursów wprowadzających do uczenia maszynowego. Andrew Ng omawia podstawy algorytmów i strategie wyboru algorytmu w zależności od problemu (klasyfikacja, regresja, klasteryzacja). 

- **Udemy: "Data Science and Machine Learning Bootcamp" – Jose Portilla**
  - Kurs zawiera praktyczne przykłady i projekty z algorytmami uczenia maszynowego, oferując krok po kroku wyjaśnienie, jak wybrać i dostroić odpowiedni model.

#### 11.4. **Blogi techniczne i portale dla specjalistów**
Blogi i portale takie jak Towards Data Science czy Machine Learning Mastery oferują praktyczne porady i często publikują przewodniki krok po kroku dotyczące wyboru i implementacji algorytmów.

- **"How to Choose Machine Learning Algorithms" – Machine Learning Mastery**
  - Artykuł dostarcza praktycznych porad dotyczących wyboru algorytmu na podstawie charakterystyki problemu (np. rozmiaru zbioru danych, rodzaju danych, wymaganej interpretowalności modelu). Autor przedstawia porównanie najpopularniejszych algorytmów, takich jak regresja logistyczna, drzewa decyzyjne, lasy losowe i algorytmy gradient boosting.

- **"An Overview of Machine Learning Algorithms" – Towards Data Science**
  - Blog ten oferuje szeroki przegląd dostępnych algorytmów, takich jak k-NN, SVM, drzewa decyzyjne i regresja. Zawiera również przewodnik na temat tego, kiedy stosować konkretne algorytmy w zależności od zadania i danych.

#### 11.5. **Dokumentacja narzędzi programistycznych**
Dokumentacja narzędzi takich jak **scikit-learn**, **TensorFlow** i **PyTorch** to doskonałe źródła informacji o praktycznej implementacji algorytmów. Dostarczają szczegółowych wyjaśnień dotyczących parametrów, metod optymalizacji oraz przykładów implementacji.

- **Scikit-learn Documentation**
  - Dokumentacja scikit-learn jest świetnym zasobem do wyboru algorytmu. Oferuje przegląd algorytmów klasyfikacyjnych, regresyjnych i klasteryzacyjnych, a także wskazówki dotyczące dostosowywania modeli za pomocą tuningu hiperparametrów.
  
- **Kaggle**
  - **Kaggle Notebooks** i **Kaggle Competitions** to źródło praktycznej wiedzy, gdzie użytkownicy mogą zobaczyć zastosowania różnych algorytmów w rzeczywistych projektach. Kaggle często służy jako narzędzie do eksperymentowania z różnymi modelami i obserwowania ich wydajności w konkretnych zadaniach.

#### 11.6. **Interaktywne narzędzia i diagramy**
Niektóre narzędzia i diagramy pomagają w intuicyjny sposób wybrać algorytm na podstawie danych i problemu.

- **Scikit-learn "Choosing the Right Estimator" Diagram**
  - **Scikit-learn** oferuje interaktywny diagram pomagający wybrać odpowiedni algorytm na podstawie typu danych i rodzaju problemu (klasyfikacja, regresja, klasteryzacja). Ten przewodnik jest prosty w użyciu i pozwala na szybkie znalezienie odpowiedniego algorytmu bez konieczności przeszukiwania dokumentacji.

---

© 2024 Marian Witkowski - wszelkie prawa zastrzeżone